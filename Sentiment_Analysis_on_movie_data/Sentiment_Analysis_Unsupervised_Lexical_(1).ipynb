{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Sentiment_Analysis_Unsupervised_Lexical (1).ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mivvNUEJi3Fo"
      },
      "source": [
        "# Import necessary depencencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOFIN9vei3F2",
        "outputId": "22357ac6-44d6-4c73-9b14-3d3733924099"
      },
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from contractions import CONTRACTION_MAP\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "nlp = spacy.load('en', parse = False, tag=False, entity=False)\n",
        "tokenizer = ToktokTokenizer()\n",
        "stopword_list = nltk.corpus.stopwords.words('english')\n",
        "stopword_list.remove('no')\n",
        "stopword_list.remove('not')\n",
        "\n",
        "import text_normalizer as tn\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2, linewidth=80)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AHbzScAi3F3"
      },
      "source": [
        "# Load and normalize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf5s_C3FvwEq",
        "outputId": "7c231148-a1ad-4a1e-eae0-c47b70c5acec"
      },
      "source": [
        "!pip install afinn"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting afinn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/e5/ffbb7ee3cca21ac6d310ac01944fb163c20030b45bda25421d725d8a859a/afinn-0.1.tar.gz (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: afinn\n",
            "  Building wheel for afinn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for afinn: filename=afinn-0.1-cp36-none-any.whl size=53451 sha256=6a805c80f2aba07fa8e903d168cbd068f16b6cb0cd5e43e068f58a6bf56d8d9d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/1c/de/428301f3333ca509dcf20ff358690eb23a1388fbcbbde008b2\n",
            "Successfully built afinn\n",
            "Installing collected packages: afinn\n",
            "Successfully installed afinn-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d47ZPdRlm9ap",
        "outputId": "bf286c7e-c02c-40ef-9f6a-0b3e080a20e4"
      },
      "source": [
        "df_1 = pd.read_csv(r'/content/sentiment.csv', error_bad_lines=False, sep='\\t')\r\n",
        "df_2 = pd.read_csv(r'/content/sentiment_tst.csv', error_bad_lines=False, sep='\\t')\r\n",
        "\r\n",
        "dataset = pd.concat([df_1, df_2]).reset_index(drop=True)\r\n",
        "dataset.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "EXW4BkeFi3F4"
      },
      "source": [
        "reviews = np.array(dataset['review'])\n",
        "sentiments = np.array(dataset['sentiment'])\n",
        "\n",
        "# extract data for model evaluation\n",
        "test_reviews = reviews[35000:]\n",
        "test_sentiments = sentiments[35000:]\n",
        "sample_review_ids = [7626, 3533, 13010]\n",
        "\n",
        "# normalize dataset\n",
        "norm_test_reviews = tn.normalize_corpus(test_reviews)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7TgpeH3WvE1-",
        "outputId": "b5d74d83-1033-4a62-965d-5caa06bde8fd"
      },
      "source": [
        "dataset['sentiment'][7626]"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "-zhJ85hVi3F4"
      },
      "source": [
        "# Sentiment Analysis with AFINN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD7u6xVwi3F4"
      },
      "source": [
        "from afinn import Afinn\n",
        "\n",
        "afn = Afinn(emoticons=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2odktNui3F5"
      },
      "source": [
        "## Predict sentiment for sample reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "Wj-WoaJsIftS",
        "outputId": "c9b4f656-0ef2-456a-b0d1-7b4395d32a3f"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "afinn_wl_url = ('https://raw.githubusercontent.com'\r\n",
        "                '/fnielsen/afinn/master/afinn/data/AFINN-111.txt')\r\n",
        "\r\n",
        "afinn_wl_df = pd.read_csv(afinn_wl_url,\r\n",
        "                          header=None, # no column names\r\n",
        "                          sep='\\t',  # tab sepeated\r\n",
        "                          names=['term', 'value']) #new column names\r\n",
        "\r\n",
        "seed = 808 # seed for sample so results are stable\r\n",
        "afinn_wl_df.sample(10, random_state = seed)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1852</th>\n",
              "      <td>regret</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1285</th>\n",
              "      <td>indifferent</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681</th>\n",
              "      <td>disappoints</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>770</th>\n",
              "      <td>doubts</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1644</th>\n",
              "      <td>outmaneuvered</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>admit</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1133</th>\n",
              "      <td>haha</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1160</th>\n",
              "      <td>haunt</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2435</th>\n",
              "      <td>wishing</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>abused</td>\n",
              "      <td>-3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               term  value\n",
              "1852         regret     -2\n",
              "1285    indifferent     -2\n",
              "681     disappoints     -2\n",
              "770          doubts     -1\n",
              "1644  outmaneuvered     -2\n",
              "55            admit     -1\n",
              "1133           haha      3\n",
              "1160          haunt     -1\n",
              "2435        wishing      1\n",
              "21           abused     -3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQJfzegEJX7d"
      },
      "source": [
        "def unique(list1): \r\n",
        "  \r\n",
        "    # intilize a null list \r\n",
        "    unique_list = [] \r\n",
        "      \r\n",
        "    # traverse for all elements \r\n",
        "    for x in list1: \r\n",
        "        # check if exists in unique_list or not \r\n",
        "        if x not in unique_list: \r\n",
        "            unique_list.append(x) \r\n",
        "    return unique_list\r\n",
        "    ## print list \r\n",
        "    #for x in unique_list: \r\n",
        "        #print (x) \r\n",
        "list1 = unique(norm_test_reviews[7626].split())"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGp-WglIQqNk"
      },
      "source": [
        "# for i in range(len(list1)):\r\n",
        "#   print (list1[i])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K8fNfxuIrPu",
        "outputId": "9d0f2021-859d-4eed-f451-3fc0dc98fabc"
      },
      "source": [
        "for review in range(0, len(list1)):\r\n",
        "  if afinn_wl_df['term'].str.contains(list1[review]).any():\r\n",
        "      print (afinn_wl_df[afinn_wl_df['term'] == list1[review]]['term'], afinn_wl_df[afinn_wl_df['term'] == list1[review]]['value'])\r\n",
        "  else:\r\n",
        "    continue\r\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Series([], Name: term, dtype: object) Series([], Name: value, dtype: int64)\n",
            "Series([], Name: term, dtype: object) Series([], Name: value, dtype: int64)\n",
            "206    avoid\n",
            "Name: term, dtype: object 206   -1\n",
            "Name: value, dtype: int64\n",
            "Series([], Name: term, dtype: object) Series([], Name: value, dtype: int64)\n",
            "2433    wish\n",
            "Name: term, dtype: object 2433    1\n",
            "Name: value, dtype: int64\n",
            "Series([], Name: term, dtype: object) Series([], Name: value, dtype: int64)\n",
            "1060    funny\n",
            "Name: term, dtype: object 1060    4\n",
            "Name: value, dtype: int64\n",
            "Series([], Name: term, dtype: object) Series([], Name: value, dtype: int64)\n",
            "1437    like\n",
            "Name: term, dtype: object 1437    2\n",
            "Name: value, dtype: int64\n",
            "Series([], Name: term, dtype: object) Series([], Name: value, dtype: int64)\n",
            "1473    lovely\n",
            "Name: term, dtype: object 1473    3\n",
            "Name: value, dtype: int64\n",
            "Series([], Name: term, dtype: object) Series([], Name: value, dtype: int64)\n",
            "1957    save\n",
            "Name: term, dtype: object 1957    2\n",
            "Name: value, dtype: int64\n",
            "Series([], Name: term, dtype: object) Series([], Name: value, dtype: int64)\n",
            "601    delayed\n",
            "Name: term, dtype: object 601   -1\n",
            "Name: value, dtype: int64\n",
            "Series([], Name: term, dtype: object) Series([], Name: value, dtype: int64)\n",
            "223    bad\n",
            "Name: term, dtype: object 223   -3\n",
            "Name: value, dtype: int64\n",
            "2397    want\n",
            "Name: term, dtype: object 2397    1\n",
            "Name: value, dtype: int64\n",
            "Series([], Name: term, dtype: object) Series([], Name: value, dtype: int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBwnmNiii3F5",
        "outputId": "6a68273e-f16d-4af0-875f-0a8a2f08878e"
      },
      "source": [
        "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
        "    print('REVIEW:', review)\n",
        "    print('Actual Sentiment:', sentiment)\n",
        "    print('Predicted Sentiment polarity:', afn.score(review))\n",
        "    print('-'*60)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "REVIEW: I seem to remember a lot of hype about this movie when it came out, but had avoided seeing it throughout the years. I wish I'd waited longer. Maybe this movie was funny in 1988, I don't know. I was younger then, but it didn't seem like the world was that different. Michelle Pfeiffer, lovely as she is, is never convincing. Mercedes Ruehl not only chews scenery, but stuffs it in her cheeks like a gerbil to save for later. Dean Stockwell is about as convincing as a mob boss as James Gandolfini would be as principal dancer for the Bolshoi. And Matthew Modine demonstrated the most pronounced case of delayed puberty I've ever seen. All in all, it's not bad enough to make you want to pluck out your eyes with a melon-baller, but it's not far off.\n",
            "Actual Sentiment: negative\n",
            "Predicted Sentiment polarity: 10.0\n",
            "------------------------------------------------------------\n",
            "REVIEW: I read Angels and Demons about 3 years ago, and I can honestly say to is one of the few books that I couldn't put down while reading.<br /><br />The movie however was pretty much what i expected, a lot of action, with somewhat of a mystery storyline. Tom Hanks plays, in my opinion, a much better role, of Professor Langdon than in The Da Vinci Code.<br /><br />You won't have to worry about this being as bad as The Da Vinci Code, this is everything that it wasn't. Much more interesting, more action, more suspense, and less of the unneeded controversy. If you haven't read the book, no worries you will still find it very interesting. And if you have read the book, well lets say you might be a little let down because I found many scenes missing that I was looking forward to.<br /><br />Overall, Pretty impressive film for any everyday movie goer. But, maybe not something too special for Dan Brown fans.\n",
            "Actual Sentiment: positive\n",
            "Predicted Sentiment polarity: 0.0\n",
            "------------------------------------------------------------\n",
            "REVIEW: What offends me most about the critics following this film is the mentioning of 'originality'. This film does not contain ONE innovating element. If, by 'originality' you refer to pathetic action scenes, overacting, gluttony in violence, blunt humor and a script beyond intellectual belief. Then, 'originality' is something Swedish film can do without.<br /><br />How Röse and Karlsson can agree to 'act' in this poor excuse for a film is a mystery to me. And how Eva Röse after the making of this film can be seen at breakfast-TV promoting it just disappoints me.<br /><br />This film doesn't contain a story, the script is illogical, stiff and last but not least, just plain bad. These two young directors have put together a quite disgusting boy-fantasy containing violence, comic-strips and trivialized psychological portraits. I wouldn't be surprised if the scene of DD masturbating in the kitchen over a micro-wave dinner actually is put there to describe the everyday life of these two overgrown cinematic nerds that pose as directors.<br /><br />I wouldn't show this movie to my worst enemy.\n",
            "Actual Sentiment: negative\n",
            "Predicted Sentiment polarity: -25.0\n",
            "------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRA1qCsbi3F6"
      },
      "source": [
        "## Predict sentiment for test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2SAqcV1i3F6"
      },
      "source": [
        "sentiment_polarity = [afn.score(review) for review in test_reviews]\n",
        "predicted_sentiments = ['positive' if score >= 1.0 else 'negative' for score in sentiment_polarity]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbquWxoli3F7"
      },
      "source": [
        "## Evaluate model performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyeK-WimxQkI"
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc \r\n",
        "\r\n",
        "from sklearn import metrics"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HaMBvZYyeGM"
      },
      "source": [
        "# Run the metrics function to display the performance of predictive modeling\r\n",
        "def display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\r\n",
        "    \r\n",
        "    total_classes = len(classes)\r\n",
        "    level_labels = [total_classes*[0], list(range(total_classes))]\r\n",
        "\r\n",
        "    cm = metrics.confusion_matrix(y_true=true_labels, y_pred=predicted_labels, \r\n",
        "                                  labels=classes)\r\n",
        "    cm_frame = pd.DataFrame(data=cm, \r\n",
        "                            columns=pd.MultiIndex(levels=[['Predicted:'], classes], \r\n",
        "                                                  codes=level_labels), \r\n",
        "                            index=pd.MultiIndex(levels=[['Actual:'], classes], \r\n",
        "                                                codes=level_labels)) \r\n",
        "    print(cm_frame)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1BZ7ueGyXcq"
      },
      "source": [
        "# Run the metrics function to display the performance of predictive modeling \r\n",
        "def get_metrics(true_labels, predicted_labels):\r\n",
        "    \r\n",
        "    print('Accuracy:', np.round(\r\n",
        "                        metrics.accuracy_score(true_labels, \r\n",
        "                                               predicted_labels),\r\n",
        "                        4))\r\n",
        "    print('Precision:', np.round(\r\n",
        "                        metrics.precision_score(true_labels, \r\n",
        "                                               predicted_labels,\r\n",
        "                                               average='weighted'),\r\n",
        "                        4))\r\n",
        "    print('Recall:', np.round(\r\n",
        "                        metrics.recall_score(true_labels, \r\n",
        "                                               predicted_labels,\r\n",
        "                                               average='weighted'),\r\n",
        "                        4))\r\n",
        "    print('F1 Score:', np.round(\r\n",
        "                        metrics.f1_score(true_labels, \r\n",
        "                                               predicted_labels,\r\n",
        "                                               average='weighted'),\r\n",
        "                        4))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2odPmIMyVN0"
      },
      "source": [
        "# Run the metrics function to display the performance of predictive modeling \r\n",
        "def display_classification_report(true_labels, predicted_labels, classes=[1,0]):\r\n",
        "\r\n",
        "    report = metrics.classification_report(y_true=true_labels, \r\n",
        "                                           y_pred=predicted_labels, \r\n",
        "                                           labels=classes) \r\n",
        "    print(report)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6GOv0-3xFzU"
      },
      "source": [
        "# Run the metrics function to display the performance of predictive modeling \r\n",
        "def display_model_performance_metrics(true_labels, predicted_labels, classes=[1,0]):\r\n",
        "    print('Model Performance metrics:')\r\n",
        "    print('-'*30)\r\n",
        "    get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)\r\n",
        "    print('\\nModel Classification report:')\r\n",
        "    print('-'*30)\r\n",
        "    display_classification_report(true_labels=true_labels, predicted_labels=predicted_labels, \r\n",
        "                                  classes=classes)\r\n",
        "    print('\\nPrediction Confusion Matrix:')\r\n",
        "    print('-'*30)\r\n",
        "    display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, \r\n",
        "                             classes=classes)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW4oNvh4i3F7",
        "outputId": "07992ea3-1141-4404-e92c-6d01ecb784ad"
      },
      "source": [
        "# Performance Metrics for Afinn\n",
        "# Please Note : the module meu is not been provided. \n",
        "display_model_performance_metrics(true_labels=test_sentiments, \n",
        "                                      predicted_labels=predicted_sentiments, \n",
        "                                  classes=['positive', 'negative'])\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Performance metrics:\n",
            "------------------------------\n",
            "Accuracy: 0.7121\n",
            "Precision: 0.7301\n",
            "Recall: 0.7121\n",
            "F1 Score: 0.7067\n",
            "\n",
            "Model Classification report:\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.66      0.85      0.75      7467\n",
            "    negative       0.79      0.58      0.67      7533\n",
            "\n",
            "    accuracy                           0.71     15000\n",
            "   macro avg       0.73      0.71      0.71     15000\n",
            "weighted avg       0.73      0.71      0.71     15000\n",
            "\n",
            "\n",
            "Prediction Confusion Matrix:\n",
            "------------------------------\n",
            "                 Predicted:         \n",
            "                   positive negative\n",
            "Actual: positive       6348     1119\n",
            "        negative       3199     4334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hIsA8_8i3F8"
      },
      "source": [
        "# Sentiment Analysis with SentiWordNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz_UM5W-i3F8",
        "outputId": "92f66e63-e2cb-4c2a-ec82-9f3a029165e1"
      },
      "source": [
        "from nltk.corpus import sentiwordnet as swn\n",
        "\n",
        "awesome = list(swn.senti_synsets('awesome', 'a'))[0]\n",
        "print('Positive Polarity Score:', awesome.pos_score())\n",
        "print('Negative Polarity Score:', awesome.neg_score())\n",
        "print('Objective Score:', awesome.obj_score())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive Polarity Score: 0.875\n",
            "Negative Polarity Score: 0.125\n",
            "Objective Score: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1xh-swEi3F9"
      },
      "source": [
        "## Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "wXaTdqPdi3F9"
      },
      "source": [
        "def analyze_sentiment_sentiwordnet_lexicon(review,\n",
        "                                           verbose=False):\n",
        "\n",
        "    # tokenize and POS tag text tokens\n",
        "    tagged_text = [(token.text, token.tag_) for token in tn.nlp(review)]\n",
        "    pos_score = neg_score = token_count = obj_score = 0\n",
        "    # get wordnet synsets based on POS tags\n",
        "    # get sentiment scores if synsets are found\n",
        "    for word, tag in tagged_text:\n",
        "        ss_set = None\n",
        "        if 'NN' in tag and list(swn.senti_synsets(word, 'n')):\n",
        "            ss_set = list(swn.senti_synsets(word, 'n'))[0]\n",
        "        elif 'VB' in tag and list(swn.senti_synsets(word, 'v')):\n",
        "            ss_set = list(swn.senti_synsets(word, 'v'))[0]\n",
        "        elif 'JJ' in tag and list(swn.senti_synsets(word, 'a')):\n",
        "            ss_set = list(swn.senti_synsets(word, 'a'))[0]\n",
        "        elif 'RB' in tag and list(swn.senti_synsets(word, 'r')):\n",
        "            ss_set = list(swn.senti_synsets(word, 'r'))[0]\n",
        "        # if senti-synset is found        \n",
        "        if ss_set:\n",
        "            # add scores for all found synsets\n",
        "            pos_score += ss_set.pos_score()\n",
        "            neg_score += ss_set.neg_score()\n",
        "            obj_score += ss_set.obj_score()\n",
        "            token_count += 1\n",
        "    \n",
        "    # aggregate final scores\n",
        "    final_score = pos_score - neg_score\n",
        "    norm_final_score = round(float(final_score) / token_count, 2)\n",
        "    final_sentiment = 'positive' if norm_final_score >= 0 else 'negative'\n",
        "    if verbose:\n",
        "        norm_obj_score = round(float(obj_score) / token_count, 2)\n",
        "        norm_pos_score = round(float(pos_score) / token_count, 2)\n",
        "        norm_neg_score = round(float(neg_score) / token_count, 2)\n",
        "        # to display results in a nice table\n",
        "        sentiment_frame = pd.DataFrame([[final_sentiment, norm_obj_score, norm_pos_score, \n",
        "                                         norm_neg_score, norm_final_score]],\n",
        "                                       columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
        "                                                             ['Predicted Sentiment', 'Objectivity',\n",
        "                                                              'Positive', 'Negative', 'Overall']], \n",
        "                                                             codes=[[0,0,0,0,0],[0,1,2,3,4]]))\n",
        "        print(sentiment_frame)\n",
        "        \n",
        "    return final_sentiment"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbKWyWsGi3F-"
      },
      "source": [
        "## Predict sentiment for sample reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htKQsaabi3F-",
        "outputId": "f96542fe-98ff-41ec-f2eb-20809e3dacf9"
      },
      "source": [
        "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
        "    print('REVIEW:', review)\n",
        "    print('Actual Sentiment:', sentiment)\n",
        "    pred = analyze_sentiment_sentiwordnet_lexicon(review, verbose=True)    \n",
        "    print('-'*60)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "REVIEW: I seem to remember a lot of hype about this movie when it came out, but had avoided seeing it throughout the years. I wish I'd waited longer. Maybe this movie was funny in 1988, I don't know. I was younger then, but it didn't seem like the world was that different. Michelle Pfeiffer, lovely as she is, is never convincing. Mercedes Ruehl not only chews scenery, but stuffs it in her cheeks like a gerbil to save for later. Dean Stockwell is about as convincing as a mob boss as James Gandolfini would be as principal dancer for the Bolshoi. And Matthew Modine demonstrated the most pronounced case of delayed puberty I've ever seen. All in all, it's not bad enough to make you want to pluck out your eyes with a melon-baller, but it's not far off.\n",
            "Actual Sentiment: negative\n",
            "     SENTIMENT STATS:                                      \n",
            "  Predicted Sentiment Objectivity Positive Negative Overall\n",
            "0            positive        0.79     0.11     0.09    0.02\n",
            "------------------------------------------------------------\n",
            "REVIEW: I read Angels and Demons about 3 years ago, and I can honestly say to is one of the few books that I couldn't put down while reading.<br /><br />The movie however was pretty much what i expected, a lot of action, with somewhat of a mystery storyline. Tom Hanks plays, in my opinion, a much better role, of Professor Langdon than in The Da Vinci Code.<br /><br />You won't have to worry about this being as bad as The Da Vinci Code, this is everything that it wasn't. Much more interesting, more action, more suspense, and less of the unneeded controversy. If you haven't read the book, no worries you will still find it very interesting. And if you have read the book, well lets say you might be a little let down because I found many scenes missing that I was looking forward to.<br /><br />Overall, Pretty impressive film for any everyday movie goer. But, maybe not something too special for Dan Brown fans.\n",
            "Actual Sentiment: positive\n",
            "     SENTIMENT STATS:                                      \n",
            "  Predicted Sentiment Objectivity Positive Negative Overall\n",
            "0            positive        0.81      0.1     0.09    0.01\n",
            "------------------------------------------------------------\n",
            "REVIEW: What offends me most about the critics following this film is the mentioning of 'originality'. This film does not contain ONE innovating element. If, by 'originality' you refer to pathetic action scenes, overacting, gluttony in violence, blunt humor and a script beyond intellectual belief. Then, 'originality' is something Swedish film can do without.<br /><br />How Röse and Karlsson can agree to 'act' in this poor excuse for a film is a mystery to me. And how Eva Röse after the making of this film can be seen at breakfast-TV promoting it just disappoints me.<br /><br />This film doesn't contain a story, the script is illogical, stiff and last but not least, just plain bad. These two young directors have put together a quite disgusting boy-fantasy containing violence, comic-strips and trivialized psychological portraits. I wouldn't be surprised if the scene of DD masturbating in the kitchen over a micro-wave dinner actually is put there to describe the everyday life of these two overgrown cinematic nerds that pose as directors.<br /><br />I wouldn't show this movie to my worst enemy.\n",
            "Actual Sentiment: negative\n",
            "     SENTIMENT STATS:                                      \n",
            "  Predicted Sentiment Objectivity Positive Negative Overall\n",
            "0            negative        0.83     0.06     0.11   -0.05\n",
            "------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owmA79spi3F_"
      },
      "source": [
        "## Predict sentiment for test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJZy6UOLi3F_"
      },
      "source": [
        "predicted_sentiments = [analyze_sentiment_sentiwordnet_lexicon(review, verbose=False) for review in norm_test_reviews]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DYcQBZMi3F_"
      },
      "source": [
        "## Evaluate model performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8cbC0edi3GA",
        "outputId": "830b93d8-51b9-4814-e9cc-d349b14f3303"
      },
      "source": [
        "# Performance Metrics on SentiWordNet\n",
        "# Please Note : the module meu is not been provided.\n",
        "display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=predicted_sentiments, \n",
        "                                  classes=['positive', 'negative'])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Performance metrics:\n",
            "------------------------------\n",
            "Accuracy: 0.6889\n",
            "Precision: 0.6921\n",
            "Recall: 0.6889\n",
            "F1 Score: 0.6878\n",
            "\n",
            "Model Classification report:\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.67      0.75      0.71      7467\n",
            "    negative       0.72      0.63      0.67      7533\n",
            "\n",
            "    accuracy                           0.69     15000\n",
            "   macro avg       0.69      0.69      0.69     15000\n",
            "weighted avg       0.69      0.69      0.69     15000\n",
            "\n",
            "\n",
            "Prediction Confusion Matrix:\n",
            "------------------------------\n",
            "                 Predicted:         \n",
            "                   positive negative\n",
            "Actual: positive       5600     1867\n",
            "        negative       2799     4734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81w7ZKDni3GA"
      },
      "source": [
        "# Sentiment Analysis with VADER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7kIxqqBi3GB",
        "outputId": "50d47dad-1a0e-4099-d9ea-f5513ab66ccc"
      },
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLF4rj4qi3GB"
      },
      "source": [
        "## Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ml5rDrati3GC"
      },
      "source": [
        "def analyze_sentiment_vader_lexicon(review, \n",
        "                                    threshold=0.1,\n",
        "                                    verbose=False):\n",
        "    # pre-process text\n",
        "    review = tn.strip_html_tags(review)\n",
        "    review = tn.remove_accented_chars(review)\n",
        "    review = tn.expand_contractions(review)\n",
        "    \n",
        "    # analyze the sentiment for review\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    scores = analyzer.polarity_scores(review)\n",
        "    # get aggregate scores and final sentiment\n",
        "    agg_score = scores['compound']\n",
        "    final_sentiment = 'positive' if agg_score >= threshold\\\n",
        "                                   else 'negative'\n",
        "    if verbose:\n",
        "        # display detailed sentiment statistics\n",
        "        positive = str(round(scores['pos'], 2)*100)+'%'\n",
        "        final = round(agg_score, 2)\n",
        "        negative = str(round(scores['neg'], 2)*100)+'%'\n",
        "        neutral = str(round(scores['neu'], 2)*100)+'%'\n",
        "        sentiment_frame = pd.DataFrame([[final_sentiment, final, positive,\n",
        "                                        negative, neutral]],\n",
        "                                        columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
        "                                                                      ['Predicted Sentiment', 'Polarity Score',\n",
        "                                                                       'Positive', 'Negative', 'Neutral']], \n",
        "                                                              codes=[[0,0,0,0,0],[0,1,2,3,4]]))\n",
        "        print(sentiment_frame)\n",
        "    \n",
        "    return final_sentiment"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B33AV_AOi3GD"
      },
      "source": [
        "## Predict sentiment for sample reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXM2EhqCi3GD",
        "outputId": "e032c15e-bb9f-4eb9-a719-04a1ae58cf27"
      },
      "source": [
        "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
        "    print('REVIEW:', review)\n",
        "    print('Actual Sentiment:', sentiment)\n",
        "    pred = analyze_sentiment_vader_lexicon(review, threshold=0.4, verbose=True)    \n",
        "    print('-'*60)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "REVIEW: I seem to remember a lot of hype about this movie when it came out, but had avoided seeing it throughout the years. I wish I'd waited longer. Maybe this movie was funny in 1988, I don't know. I was younger then, but it didn't seem like the world was that different. Michelle Pfeiffer, lovely as she is, is never convincing. Mercedes Ruehl not only chews scenery, but stuffs it in her cheeks like a gerbil to save for later. Dean Stockwell is about as convincing as a mob boss as James Gandolfini would be as principal dancer for the Bolshoi. And Matthew Modine demonstrated the most pronounced case of delayed puberty I've ever seen. All in all, it's not bad enough to make you want to pluck out your eyes with a melon-baller, but it's not far off.\n",
            "Actual Sentiment: negative\n",
            "     SENTIMENT STATS:                                                     \n",
            "  Predicted Sentiment Polarity Score             Positive Negative Neutral\n",
            "0            positive           0.82  14.000000000000002%    10.0%   76.0%\n",
            "------------------------------------------------------------\n",
            "REVIEW: I read Angels and Demons about 3 years ago, and I can honestly say to is one of the few books that I couldn't put down while reading.<br /><br />The movie however was pretty much what i expected, a lot of action, with somewhat of a mystery storyline. Tom Hanks plays, in my opinion, a much better role, of Professor Langdon than in The Da Vinci Code.<br /><br />You won't have to worry about this being as bad as The Da Vinci Code, this is everything that it wasn't. Much more interesting, more action, more suspense, and less of the unneeded controversy. If you haven't read the book, no worries you will still find it very interesting. And if you have read the book, well lets say you might be a little let down because I found many scenes missing that I was looking forward to.<br /><br />Overall, Pretty impressive film for any everyday movie goer. But, maybe not something too special for Dan Brown fans.\n",
            "Actual Sentiment: positive\n",
            "     SENTIMENT STATS:                                         \n",
            "  Predicted Sentiment Polarity Score Positive Negative Neutral\n",
            "0            positive           0.64    12.0%    10.0%   78.0%\n",
            "------------------------------------------------------------\n",
            "REVIEW: What offends me most about the critics following this film is the mentioning of 'originality'. This film does not contain ONE innovating element. If, by 'originality' you refer to pathetic action scenes, overacting, gluttony in violence, blunt humor and a script beyond intellectual belief. Then, 'originality' is something Swedish film can do without.<br /><br />How Röse and Karlsson can agree to 'act' in this poor excuse for a film is a mystery to me. And how Eva Röse after the making of this film can be seen at breakfast-TV promoting it just disappoints me.<br /><br />This film doesn't contain a story, the script is illogical, stiff and last but not least, just plain bad. These two young directors have put together a quite disgusting boy-fantasy containing violence, comic-strips and trivialized psychological portraits. I wouldn't be surprised if the scene of DD masturbating in the kitchen over a micro-wave dinner actually is put there to describe the everyday life of these two overgrown cinematic nerds that pose as directors.<br /><br />I wouldn't show this movie to my worst enemy.\n",
            "Actual Sentiment: negative\n",
            "     SENTIMENT STATS:                                         \n",
            "  Predicted Sentiment Polarity Score Positive Negative Neutral\n",
            "0            negative          -0.99     4.0%    21.0%   75.0%\n",
            "------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3uRK8Exi3GE"
      },
      "source": [
        "## Predict sentiment for test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obR9Hk9Xi3GE"
      },
      "source": [
        "predicted_sentiments = [analyze_sentiment_vader_lexicon(review, threshold=0.7, verbose=False) for review in test_reviews]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC207jUci3GE"
      },
      "source": [
        "## Evaluate model performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXfVYXrci3GF",
        "outputId": "2c794b1c-469a-4a47-d863-ea1aadf53f08"
      },
      "source": [
        "# Performance Metrics on VADER\n",
        "# Please Note : the module meu is not been provided.\n",
        "display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=predicted_sentiments, \n",
        "                                  classes=['positive', 'negative'])\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Performance metrics:\n",
            "------------------------------\n",
            "Accuracy: 0.7217\n",
            "Precision: 0.7243\n",
            "Recall: 0.7217\n",
            "F1 Score: 0.721\n",
            "\n",
            "Model Classification report:\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.70      0.77      0.73      7467\n",
            "    negative       0.75      0.67      0.71      7533\n",
            "\n",
            "    accuracy                           0.72     15000\n",
            "   macro avg       0.72      0.72      0.72     15000\n",
            "weighted avg       0.72      0.72      0.72     15000\n",
            "\n",
            "\n",
            "Prediction Confusion Matrix:\n",
            "------------------------------\n",
            "                 Predicted:         \n",
            "                   positive negative\n",
            "Actual: positive       5773     1694\n",
            "        negative       2481     5052\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-9SZoac2b6z"
      },
      "source": [
        "Model Performance metrics:\r\n",
        "------------------------------\r\n",
        "Accuracy: 0.7246\r\n",
        "Precision: 0.7247\r\n",
        "Recall: 0.7246\r\n",
        "F1 Score: 0.7246\r\n",
        "\r\n",
        "Model Classification report:\r\n",
        "------------------------------\r\n",
        "              precision    recall  f1-score   support\r\n",
        "\r\n",
        "    positive       0.72      0.73      0.73      7467\r\n",
        "    negative       0.73      0.72      0.72      7533\r\n",
        "\r\n",
        "    accuracy                           0.72     15000\r\n",
        "   macro avg       0.72      0.72      0.72     15000\r\n",
        "weighted avg       0.72      0.72      0.72     15000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7JUX8OlEXsF",
        "outputId": "61946c1c-b0e9-48f8-e59f-a9cfec15ab4a"
      },
      "source": [
        "!pip install stanza"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stanza\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/8b/3a9e7a8d8cb14ad6afffc3983b7a7322a3a24d94ebc978a70746fcffc085/stanza-1.1.1-py3-none-any.whl (227kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stanza) (1.19.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stanza) (4.41.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from stanza) (3.12.4)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from stanza) (1.7.0+cu101)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2020.12.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (51.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (0.8)\n",
            "Installing collected packages: stanza\n",
            "Successfully installed stanza-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKEh7gfBCiRc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}