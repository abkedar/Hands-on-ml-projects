{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Predictive_Modeling_for_Sentiment_Analysis.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Oy_cnwscRoD"
      },
      "source": [
        "# Import necessary dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "nHKycl44cRoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb2589fe-4c87-41bb-c923-99f21807bbc6"
      },
      "source": [
        "# Import required Libraries\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from contractions import CONTRACTION_MAP\n",
        "import unicodedata\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "nlp = spacy.load('en', parse = False, tag=False, entity=False)\n",
        "tokenizer = ToktokTokenizer()\n",
        "stopword_list = nltk.corpus.stopwords.words('english')\n",
        "stopword_list.remove('no')\n",
        "stopword_list.remove('not')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS9IDAV7k-wP",
        "outputId": "204cd223-2a02-4d39-ea07-5af45bd7cd2e"
      },
      "source": [
        "# Load train Data set\r\n",
        "df_tr = pd.read_csv(\"/content/sentiment.csv\", error_bad_lines=False, sep='\\t')\r\n",
        "#df.head()\r\n",
        "\r\n",
        "df_tr.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHh-mv72zsd_"
      },
      "source": [
        "# load test data\r\n",
        "df_ts = pd.read_csv(\"/content/sentiment_tst.csv\", error_bad_lines=False, sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks5Ddv8E9Jlu",
        "outputId": "a0a9b493-13b8-4c94-ebdc-ea199e4d05dd"
      },
      "source": [
        "df1 = pd.concat([df_tr, df_ts]).reset_index(drop=True)\r\n",
        "df1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1PwW9759SbV",
        "outputId": "3b6ab44e-4fd2-4036-c24c-2be57ed33267"
      },
      "source": [
        "df = df1[:35000]\r\n",
        "df_ts = df1[35000:]\r\n",
        "print(df.shape)\r\n",
        "print(df_ts.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35000, 3)\n",
            "(15000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reuLBbg2cRoP"
      },
      "source": [
        "# Cleaning Text - strip HTML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ExoBRd4lcRoP"
      },
      "source": [
        "# function to remove html code in the text rwas data\n",
        "def strip_html_tags(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")#.get_text()\n",
        "    stripped_text = soup.get_text()\n",
        "    return stripped_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqsBqWRlcRoQ"
      },
      "source": [
        "# Removing accented characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "5_s-ujGLcRoQ"
      },
      "source": [
        "# Function bring the text to normal string format\n",
        "def remove_accented_chars(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WhogiJFcRoQ"
      },
      "source": [
        "# Expanding Contractions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "dsp9mUqTcRoR"
      },
      "source": [
        "# Function text data contain word like don't, does'nt, so convert them to do not, does not\n",
        "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
        "    \n",
        "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
        "                                      flags=re.IGNORECASE|re.DOTALL)\n",
        "    def expand_match(contraction):\n",
        "        match = contraction.group(0)\n",
        "        first_char = match[0]\n",
        "        expanded_contraction = contraction_mapping.get(match)\\\n",
        "                                if contraction_mapping.get(match)\\\n",
        "                                else contraction_mapping.get(match.lower())                       \n",
        "        expanded_contraction = first_char+expanded_contraction[1:]\n",
        "        return expanded_contraction\n",
        "        \n",
        "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
        "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
        "    return expanded_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWNNXNjGcRoR"
      },
      "source": [
        "# Removing Special Characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "FRb_hlwwcRoS"
      },
      "source": [
        "# Function remove special character other then alphabet and number\n",
        "def remove_special_characters(text):\n",
        "    text = re.sub('[^a-zA-z0-9\\s]', '', text)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmdhORKLcRoS"
      },
      "source": [
        "# Lemmatizing text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Kb0p_U7_cRoT"
      },
      "source": [
        "# Function bring the pural, abjective word to root form.\n",
        "def lemmatize_text(text):\n",
        "    text = nlp(text)\n",
        "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggTrklg7cRoT"
      },
      "source": [
        "# Removing Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "PUSv7375cRoT"
      },
      "source": [
        "# Function to remove stopword using NLTK Libraries\n",
        "def remove_stopwords(text, is_lower_case=False):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    if is_lower_case:\n",
        "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
        "    filtered_text = ' '.join(filtered_tokens)    \n",
        "    return filtered_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z67xaNFKcRoU"
      },
      "source": [
        "# Normalize text corpus - tying it all together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "9eUcYO2qcRoU"
      },
      "source": [
        "# Combining all above function in above function in one and carry the Text cleaning data\n",
        "def normalize_corpus(corpus, html_stripping=True, contraction_expansion=True,\n",
        "                     accented_char_removal=True, text_lower_case=True, \n",
        "                     text_lemmatization=True, special_char_removal=True, \n",
        "                     stopword_removal=True):\n",
        "    \n",
        "    normalized_corpus = []\n",
        "    # normalize each document in the corpus\n",
        "    for doc in corpus:\n",
        "        # strip HTML\n",
        "        if html_stripping:\n",
        "            doc = strip_html_tags(doc)\n",
        "        # remove accented characters\n",
        "        if accented_char_removal:\n",
        "            doc = remove_accented_chars(doc)\n",
        "        # expand contractions    \n",
        "        if contraction_expansion:\n",
        "            doc = expand_contractions(doc)\n",
        "        # lowercase the text    \n",
        "        if text_lower_case:\n",
        "            doc = doc.lower()\n",
        "        # remove extra newlines\n",
        "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
        "        # insert spaces between special characters to isolate them    \n",
        "        special_char_pattern = re.compile(r'([{.(-)!}])')\n",
        "        doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
        "        # lemmatize text\n",
        "        if text_lemmatization:\n",
        "            doc = lemmatize_text(doc)\n",
        "        # remove special characters    \n",
        "        if special_char_removal:\n",
        "            doc = remove_special_characters(doc)  \n",
        "        # remove extra whitespace\n",
        "        doc = re.sub(' +', ' ', doc)\n",
        "        # remove stopwords\n",
        "        if stopword_removal:\n",
        "            doc = remove_stopwords(doc, is_lower_case=text_lower_case)\n",
        "            \n",
        "        normalized_corpus.append(doc)\n",
        "        \n",
        "    return normalized_corpus\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WRc5tzucRoV"
      },
      "source": [
        "# Model predictions of movie review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUpdAzJl4YUV"
      },
      "source": [
        "# Import Scikit Learn Libraries for model prediction.\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\r\n",
        "\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.base import clone\r\n",
        "from sklearn.metrics import roc_curve, auc\r\n",
        "\r\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldOjGeJEcRoX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "882b1cd4-5ec3-4407-f59f-c9c5cd8d09db"
      },
      "source": [
        "# Run the Cleaning process function of text data in train data set\r\n",
        "df['cleaned_re'] = normalize_corpus(df['review'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5es_0Fvs9Mt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2234c05e-deae-4b62-ee23-045d7f55c82b"
      },
      "source": [
        "# Run the Cleaning process function of text data in test data set\r\n",
        "df_ts['cleaned_re'] = normalize_corpus(df_ts['review'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "WgA3q_Lk55eU",
        "outputId": "91d61b09-bb35-411c-d641-53944c4afabe"
      },
      "source": [
        "df_ts.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>cleaned_re</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>35000</th>\n",
              "      <td>10000</td>\n",
              "      <td>Worthless movie. A complete waste of time and ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>worthless movie complete waste time nothing ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35001</th>\n",
              "      <td>10001</td>\n",
              "      <td>This crock of doodoo won a award? They must ha...</td>\n",
              "      <td>negative</td>\n",
              "      <td>crock doodoo win award must desperate give awa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35002</th>\n",
              "      <td>10002</td>\n",
              "      <td>A traveling couple (Horton and Hamilton)stumbl...</td>\n",
              "      <td>negative</td>\n",
              "      <td>travel couple horton hamilton stumble onto tow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35003</th>\n",
              "      <td>10003</td>\n",
              "      <td>The scientist Charles and his wife (or assista...</td>\n",
              "      <td>negative</td>\n",
              "      <td>scientist charles wife assistant marissa recei...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35004</th>\n",
              "      <td>10004</td>\n",
              "      <td>Comparisons to the original series are inevita...</td>\n",
              "      <td>negative</td>\n",
              "      <td>comparison original series inevitable shame di...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...                                         cleaned_re\n",
              "35000       10000  ...  worthless movie complete waste time nothing ex...\n",
              "35001       10001  ...  crock doodoo win award must desperate give awa...\n",
              "35002       10002  ...  travel couple horton hamilton stumble onto tow...\n",
              "35003       10003  ...  scientist charles wife assistant marissa recei...\n",
              "35004       10004  ...  comparison original series inevitable shame di...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C73caT8h5l1-"
      },
      "source": [
        "# take a peek at the data\r\n",
        "reviews = np.array(df['cleaned_re'])\r\n",
        "sentiments = np.array(df['sentiment'])\r\n",
        "\r\n",
        "reviews_ts = np.array(df_ts['cleaned_re'])\r\n",
        "sentiments_ts = np.array(df_ts['sentiment'])\r\n",
        "\r\n",
        "# build train and test datasets\r\n",
        "norm_train_reviews = reviews\r\n",
        "train_sentiments = sentiments\r\n",
        "norm_test_reviews = reviews_ts\r\n",
        "test_sentiments = sentiments_ts\r\n",
        "\r\n",
        "# normalize datasets\r\n",
        "#norm_train_reviews = tn.normalize_corpus(train_reviews)\r\n",
        "#norm_test_reviews = tn.normalize_corpus(test_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5yhUlg09Etm"
      },
      "source": [
        "# build BOW features on train reviews\r\n",
        "cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0, ngram_range=(1,2))\r\n",
        "cv_train_features = cv.fit_transform(norm_train_reviews)\r\n",
        "\r\n",
        "# build TFIDF features on train reviews\r\n",
        "tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0, ngram_range=(1,2),\r\n",
        "                     sublinear_tf=True)\r\n",
        "tv_train_features = tv.fit_transform(norm_train_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9anuBLH4i05"
      },
      "source": [
        "# transform test reviews into features\r\n",
        "cv_test_features = cv.transform(norm_test_reviews)\r\n",
        "tv_test_features = tv.transform(norm_test_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3eoLt814KDX"
      },
      "source": [
        "def train_predict_model(classifier, \r\n",
        "                        train_features, train_labels, \r\n",
        "                        test_features, test_labels):\r\n",
        "    # build model    \r\n",
        "    classifier.fit(train_features, train_labels)\r\n",
        "    # predict using model\r\n",
        "    predictions = classifier.predict(test_features) \r\n",
        "    return predictions "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZMmcNtoAes4"
      },
      "source": [
        "# Run the metrics function to display the performance of predictive modeling \r\n",
        "def display_classification_report(true_labels, predicted_labels, classes=[1,0]):\r\n",
        "\r\n",
        "    report = metrics.classification_report(y_true=true_labels, \r\n",
        "                                           y_pred=predicted_labels, \r\n",
        "                                           labels=classes) \r\n",
        "    print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF-OK5-TAlbf"
      },
      "source": [
        "# Run the metrics function to display the performance of predictive modeling\r\n",
        "def display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\r\n",
        "    \r\n",
        "    total_classes = len(classes)\r\n",
        "    level_labels = [total_classes*[0], list(range(total_classes))]\r\n",
        "\r\n",
        "    cm = metrics.confusion_matrix(y_true=true_labels, y_pred=predicted_labels, \r\n",
        "                                  labels=classes)\r\n",
        "    cm_frame = pd.DataFrame(data=cm, \r\n",
        "                            columns=pd.MultiIndex(levels=[['Predicted:'], classes], \r\n",
        "                                                  codes=level_labels), \r\n",
        "                            index=pd.MultiIndex(levels=[['Actual:'], classes], \r\n",
        "                                                codes=level_labels)) \r\n",
        "    print(cm_frame) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vj8CWz3-dMJ"
      },
      "source": [
        "# Run the metrics function to display the performance of predictive modeling \r\n",
        "def display_model_performance_metrics(true_labels, predicted_labels, classes=[1,0]):\r\n",
        "    print('Model Performance metrics:')\r\n",
        "    print('-'*30)\r\n",
        "    get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)\r\n",
        "    print('\\nModel Classification report:')\r\n",
        "    print('-'*30)\r\n",
        "    display_classification_report(true_labels=true_labels, predicted_labels=predicted_labels, \r\n",
        "                                  classes=classes)\r\n",
        "    print('\\nPrediction Confusion Matrix:')\r\n",
        "    print('-'*30)\r\n",
        "    display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, \r\n",
        "                             classes=classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8G3ftCq-uno"
      },
      "source": [
        "# Run the metrics function to display the performance of predictive modeling \r\n",
        "def get_metrics(true_labels, predicted_labels):\r\n",
        "    \r\n",
        "    print('Accuracy:', np.round(\r\n",
        "                        metrics.accuracy_score(true_labels, \r\n",
        "                                               predicted_labels),\r\n",
        "                        4))\r\n",
        "    print('Precision:', np.round(\r\n",
        "                        metrics.precision_score(true_labels, \r\n",
        "                                               predicted_labels,\r\n",
        "                                               average='weighted'),\r\n",
        "                        4))\r\n",
        "    print('Recall:', np.round(\r\n",
        "                        metrics.recall_score(true_labels, \r\n",
        "                                               predicted_labels,\r\n",
        "                                               average='weighted'),\r\n",
        "                        4))\r\n",
        "    print('F1 Score:', np.round(\r\n",
        "                        metrics.f1_score(true_labels, \r\n",
        "                                               predicted_labels,\r\n",
        "                                               average='weighted'),\r\n",
        "                        4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwL5hnaW9bV1",
        "outputId": "88c803cf-8c04-4fc0-e42d-9157d38cbb11"
      },
      "source": [
        "print('BOW model:> Train features shape:', cv_train_features.shape, ' Test features shape:', cv_test_features.shape)\r\n",
        "print('TFIDF model:> Train features shape:', tv_train_features.shape, ' Test features shape:', tv_test_features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BOW model:> Train features shape: (35000, 2122607)  Test features shape: (15000, 2122607)\n",
            "TFIDF model:> Train features shape: (35000, 2122607)  Test features shape: (15000, 2122607)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJySmWUA9qQq"
      },
      "source": [
        "### Model Training, Prediction and Performance Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w26OcM3p9eIc"
      },
      "source": [
        "# Predictive modeling\r\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\r\n",
        "\r\n",
        "lr = LogisticRegression(penalty='l2', max_iter=100, C=1)\r\n",
        "svm = SGDClassifier(loss='hinge', max_iter=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waOV1F3Z9wVk",
        "outputId": "b49442b2-79b6-4896-a7d4-581527b8e12d"
      },
      "source": [
        "# Logistic Regression model on BOW features\r\n",
        "# Please Note : the module meu is not been provided. \r\n",
        "lr_bow_predictions = train_predict_model(classifier=lr, \r\n",
        "                                             train_features=cv_train_features, train_labels=train_sentiments,\r\n",
        "                                             test_features=cv_test_features, test_labels=test_sentiments)\r\n",
        "display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=lr_bow_predictions,\r\n",
        "                                      classes=['positive', 'negative'])\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model Performance metrics:\n",
            "------------------------------\n",
            "Accuracy: 0.9003\n",
            "Precision: 0.9004\n",
            "Recall: 0.9003\n",
            "F1 Score: 0.9003\n",
            "\n",
            "Model Classification report:\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.89      0.91      0.90      7467\n",
            "    negative       0.91      0.89      0.90      7533\n",
            "\n",
            "    accuracy                           0.90     15000\n",
            "   macro avg       0.90      0.90      0.90     15000\n",
            "weighted avg       0.90      0.90      0.90     15000\n",
            "\n",
            "\n",
            "Prediction Confusion Matrix:\n",
            "------------------------------\n",
            "                 Predicted:         \n",
            "                   positive negative\n",
            "Actual: positive       6791      676\n",
            "        negative        820     6713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mJ28ixe_5h0",
        "outputId": "134b69e7-4af2-4bac-f0c9-8376b00e59cd"
      },
      "source": [
        "# Logistic Regression model on TF-IDF features\r\n",
        "# Please Note : the module meu is not been provided.\r\n",
        "lr_tfidf_predictions = train_predict_model(classifier=lr, \r\n",
        "                                               train_features=tv_train_features, train_labels=train_sentiments,\r\n",
        "                                               test_features=tv_test_features, test_labels=test_sentiments)\r\n",
        "display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=lr_tfidf_predictions,\r\n",
        "                                      classes=['positive', 'negative'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Performance metrics:\n",
            "------------------------------\n",
            "Accuracy: 0.894\n",
            "Precision: 0.8942\n",
            "Recall: 0.894\n",
            "F1 Score: 0.894\n",
            "\n",
            "Model Classification report:\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.89      0.90      0.89      7467\n",
            "    negative       0.90      0.88      0.89      7533\n",
            "\n",
            "    accuracy                           0.89     15000\n",
            "   macro avg       0.89      0.89      0.89     15000\n",
            "weighted avg       0.89      0.89      0.89     15000\n",
            "\n",
            "\n",
            "Prediction Confusion Matrix:\n",
            "------------------------------\n",
            "                 Predicted:         \n",
            "                   positive negative\n",
            "Actual: positive       6747      720\n",
            "        negative        870     6663\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-feHIRIxCIIT",
        "outputId": "13e419eb-9e06-43ed-ec06-5ef40f2ec794"
      },
      "source": [
        "# SVM model on BOW features\r\n",
        "# Please Note : the module meu is not been provided.\r\n",
        "svm_bow_predictions = train_predict_model(classifier=svm, \r\n",
        "                                             train_features=cv_train_features, train_labels=train_sentiments,\r\n",
        "                                             test_features=cv_test_features, test_labels=test_sentiments)\r\n",
        "display_model_performance_metrics(true_labels=test_sentiments, \r\n",
        "                                      predicted_labels=svm_bow_predictions,\r\n",
        "                                      classes=['positive', 'negative'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Performance metrics:\n",
            "------------------------------\n",
            "Accuracy: 0.8923\n",
            "Precision: 0.8924\n",
            "Recall: 0.8923\n",
            "F1 Score: 0.8923\n",
            "\n",
            "Model Classification report:\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.89      0.90      0.89      7467\n",
            "    negative       0.90      0.88      0.89      7533\n",
            "\n",
            "    accuracy                           0.89     15000\n",
            "   macro avg       0.89      0.89      0.89     15000\n",
            "weighted avg       0.89      0.89      0.89     15000\n",
            "\n",
            "\n",
            "Prediction Confusion Matrix:\n",
            "------------------------------\n",
            "                 Predicted:         \n",
            "                   positive negative\n",
            "Actual: positive       6720      747\n",
            "        negative        869     6664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLEcwKQhCddM",
        "outputId": "2023408c-fd73-496b-a042-937b6ede414a"
      },
      "source": [
        "# SVM model on TF-IDF features\r\n",
        "# Please Note : the module meu is not been provided.\r\n",
        "svm_tfidf_predictions = train_predict_model(classifier=svm, \r\n",
        "                                                train_features=tv_train_features, train_labels=train_sentiments,\r\n",
        "                                                test_features=tv_test_features, test_labels=test_sentiments)\r\n",
        "display_model_performance_metrics(true_labels=test_sentiments, \r\n",
        "                                      predicted_labels=svm_tfidf_predictions,\r\n",
        "                                      classes=['positive', 'negative'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Performance metrics:\n",
            "------------------------------\n",
            "Accuracy: 0.8979\n",
            "Precision: 0.8983\n",
            "Recall: 0.8979\n",
            "F1 Score: 0.8978\n",
            "\n",
            "Model Classification report:\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.88      0.91      0.90      7467\n",
            "    negative       0.91      0.88      0.90      7533\n",
            "\n",
            "    accuracy                           0.90     15000\n",
            "   macro avg       0.90      0.90      0.90     15000\n",
            "weighted avg       0.90      0.90      0.90     15000\n",
            "\n",
            "\n",
            "Prediction Confusion Matrix:\n",
            "------------------------------\n",
            "                 Predicted:         \n",
            "                   positive negative\n",
            "Actual: positive       6822      645\n",
            "        negative        887     6646\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQIhEV0VCpAk"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from xgboost import XGBClassifier\r\n",
        "\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YbynnR6OTOu"
      },
      "source": [
        "randomclassifier=RandomForestClassifier(n_estimators=300,criterion='entropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_ye7Sg0OpHl",
        "outputId": "945e6dc4-9709-4acc-bca5-3652dd67bd7a"
      },
      "source": [
        "# Random Forest model on TF-IDF features\r\n",
        "# Please Note : the module meu is not been provided.\r\n",
        "svm_tfidf_predictions = train_predict_model(classifier=randomclassifier, \r\n",
        "                                                train_features=tv_train_features, train_labels=train_sentiments,\r\n",
        "                                                test_features=tv_test_features, test_labels=test_sentiments)\r\n",
        "display_model_performance_metrics(true_labels=test_sentiments, \r\n",
        "                                      predicted_labels=svm_tfidf_predictions,\r\n",
        "                                      classes=['positive', 'negative'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Performance metrics:\n",
            "------------------------------\n",
            "Accuracy: 0.8765\n",
            "Precision: 0.8766\n",
            "Recall: 0.8765\n",
            "F1 Score: 0.8765\n",
            "\n",
            "Model Classification report:\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.88      0.87      0.88      7467\n",
            "    negative       0.87      0.88      0.88      7533\n",
            "\n",
            "    accuracy                           0.88     15000\n",
            "   macro avg       0.88      0.88      0.88     15000\n",
            "weighted avg       0.88      0.88      0.88     15000\n",
            "\n",
            "\n",
            "Prediction Confusion Matrix:\n",
            "------------------------------\n",
            "                 Predicted:         \n",
            "                   positive negative\n",
            "Actual: positive       6489      978\n",
            "        negative        874     6659\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SnzoFlzPESz",
        "outputId": "791f5d97-7e3b-4731-f05f-d9cae5c44b0b"
      },
      "source": [
        "# Randome Forest model on BOW features\r\n",
        "# Please Note : the module meu is not been provided.\r\n",
        "random_bow_predictions = train_predict_model(classifier=randomclassifier, \r\n",
        "                                             train_features=cv_train_features, train_labels=train_sentiments,\r\n",
        "                                             test_features=cv_test_features, test_labels=test_sentiments)\r\n",
        "display_model_performance_metrics(true_labels=test_sentiments, \r\n",
        "                                      predicted_labels=random_bow_predictions,\r\n",
        "                                      classes=['positive', 'negative'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Performance metrics:\n",
            "------------------------------\n",
            "Accuracy: 0.8767\n",
            "Precision: 0.877\n",
            "Recall: 0.8767\n",
            "F1 Score: 0.8767\n",
            "\n",
            "Model Classification report:\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.87      0.89      0.88      7467\n",
            "    negative       0.89      0.86      0.88      7533\n",
            "\n",
            "    accuracy                           0.88     15000\n",
            "   macro avg       0.88      0.88      0.88     15000\n",
            "weighted avg       0.88      0.88      0.88     15000\n",
            "\n",
            "\n",
            "Prediction Confusion Matrix:\n",
            "------------------------------\n",
            "                 Predicted:         \n",
            "                   positive negative\n",
            "Actual: positive       6643      824\n",
            "        negative       1026     6507\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FALjdhKEQZss"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn import svm\r\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woHcZ_AKk6wb"
      },
      "source": [
        "clf_tree = DecisionTreeClassifier(max_features='auto', random_state=0)\r\n",
        "clf_svm = svm.SVC()\r\n",
        "clf_gnb = GaussianNB()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNM-Z-g7lhmt",
        "outputId": "8d99ddbb-f0d0-4cd1-fef3-24813f1fe55c"
      },
      "source": [
        "# Random Forest model on TF-IDF features\r\n",
        "# Please Note : the module meu is not been provided.\r\n",
        "svm_tfidf_predictions = train_predict_model(classifier=clf_tree, \r\n",
        "                                                train_features=tv_train_features, train_labels=train_sentiments,\r\n",
        "                                                test_features=tv_test_features, test_labels=test_sentiments)\r\n",
        "display_model_performance_metrics(true_labels=test_sentiments, \r\n",
        "                                      predicted_labels=svm_tfidf_predictions,\r\n",
        "                                      classes=['positive', 'negative'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Performance metrics:\n",
            "------------------------------\n",
            "Accuracy: 0.6334\n",
            "Precision: 0.6334\n",
            "Recall: 0.6334\n",
            "F1 Score: 0.6334\n",
            "\n",
            "Model Classification report:\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.63      0.63      0.63      7467\n",
            "    negative       0.64      0.63      0.63      7533\n",
            "\n",
            "    accuracy                           0.63     15000\n",
            "   macro avg       0.63      0.63      0.63     15000\n",
            "weighted avg       0.63      0.63      0.63     15000\n",
            "\n",
            "\n",
            "Prediction Confusion Matrix:\n",
            "------------------------------\n",
            "                 Predicted:         \n",
            "                   positive negative\n",
            "Actual: positive       4735     2732\n",
            "        negative       2767     4766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ7E8zvpllTZ",
        "outputId": "6926cb19-45a8-47f9-9267-33a073adfbbb"
      },
      "source": [
        "# Random Forest model on TF-IDF features\r\n",
        "# Please Note : the module meu is not been provided.\r\n",
        "svm_tfidf_predictions = train_predict_model(classifier=clf_svm, \r\n",
        "                                                train_features=tv_train_features, train_labels=train_sentiments,\r\n",
        "                                                test_features=tv_test_features, test_labels=test_sentiments)\r\n",
        "display_model_performance_metrics(true_labels=test_sentiments, \r\n",
        "                                      predicted_labels=svm_tfidf_predictions,\r\n",
        "                                      classes=['positive', 'negative'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Performance metrics:\n",
            "------------------------------\n",
            "Accuracy: 0.9016\n",
            "Precision: 0.9018\n",
            "Recall: 0.9016\n",
            "F1 Score: 0.9016\n",
            "\n",
            "Model Classification report:\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.89      0.91      0.90      7467\n",
            "    negative       0.91      0.89      0.90      7533\n",
            "\n",
            "    accuracy                           0.90     15000\n",
            "   macro avg       0.90      0.90      0.90     15000\n",
            "weighted avg       0.90      0.90      0.90     15000\n",
            "\n",
            "\n",
            "Prediction Confusion Matrix:\n",
            "------------------------------\n",
            "                 Predicted:         \n",
            "                   positive negative\n",
            "Actual: positive       6817      650\n",
            "        negative        826     6707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "iBQj1gGOlmNs",
        "outputId": "a44d34cc-e792-4bbf-c39f-7f978154e053"
      },
      "source": [
        "# Random Forest model on TF-IDF features\r\n",
        "# Please Note : the module meu is not been provided.\r\n",
        "svm_tfidf_predictions = train_predict_model(classifier=clf_gnb, \r\n",
        "                                                train_features=tv_train_features.toarray(), train_labels=train_sentiments,\r\n",
        "                                                test_features=tv_test_features.toarray(), test_labels=test_sentiments)\r\n",
        "display_model_performance_metrics(true_labels=test_sentiments, \r\n",
        "                                      predicted_labels=svm_tfidf_predictions,\r\n",
        "                                      classes=['positive', 'negative'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4f83367f3e9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Random Forest model on TF-IDF features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Please Note : the module meu is not been provided.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m svm_tfidf_predictions = train_predict_model(classifier=clf_gnb, \n\u001b[0m\u001b[1;32m      4\u001b[0m                                                 \u001b[0mtrain_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtv_train_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sentiments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                 test_features=tv_test_features.toarray(), test_labels=test_sentiments)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_predict_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "Kv-kHCKRBXx6",
        "outputId": "a74a794e-6ba0-46ec-8d93-df43890d99f4"
      },
      "source": [
        "clf_svm_p = svm.SVC(kernel='sigmoid', C=1, random_state=42)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-899ca565d8ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf_svm_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'svm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyueA1nWdSSu"
      },
      "source": [
        "# Random Forest model on TF-IDF features\r\n",
        "# Please Note : the module meu is not been provided.\r\n",
        "svm_tfidf_predictions = train_predict_model(classifier=clf_svm_p, \r\n",
        "                                                train_features=tv_train_features, train_labels=train_sentiments,\r\n",
        "                                                test_features=tv_test_features, test_labels=test_sentiments)\r\n",
        "display_model_performance_metrics(true_labels=test_sentiments, \r\n",
        "                                      predicted_labels=svm_tfidf_predictions,\r\n",
        "                                      classes=['positive', 'negative'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nLbasLXdqkY"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\r\n",
        "clf_pipe = make_pipeline(lr, svm.SVC(gamma='auto'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCx6OKSzd7EO"
      },
      "source": [
        "# Random Forest model on TF-IDF features\r\n",
        "# Please Note : the module meu is not been provided.\r\n",
        "svm_tfidf_predictions = train_predict_model(classifier=clf_pipe, \r\n",
        "                                                train_features=tv_train_features, train_labels=train_sentiments,\r\n",
        "                                                test_features=tv_test_features, test_labels=test_sentiments)\r\n",
        "display_model_performance_metrics(true_labels=test_sentiments, \r\n",
        "                                      predicted_labels=svm_tfidf_predictions,\r\n",
        "                                      classes=['positive', 'negative'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}